# UGI_Corpus
The Unobtrusive Group Interaction (UGI) Corpus

Studying group dynamics requires fine-grained spatial and temporal understanding of human behavior. Social psychologists studying human interaction patterns in face-to-face group meetings often find themselves struggling with huge volumes of data that require many hours of tedious manual coding. There are only a few publicly available multi-modal datasets of face-to-face group meetings that enable the development of automated methods to study verbal and non-verbal human behavior.  Here we present a new, publicly available multi-modal dataset for group dynamics study that differs from previous datasets in its use of ceiling-mounted, unobtrusive depth sensors.  These can be used for fine-grained analysis of head and body pose and gestures, without any concerns about participants' privacy or inhibited behavior. The dataset is complemented by synchronized and time-stamped meeting transcripts that allow analysis of spoken content. The dataset comprises 22 group meetings in which participants perform a standard collaborative group task designed to measure leadership and productivity.  Participants' post-task questionnaires, including demographic information, are also provided as part of the dataset.  

For more details about the dataset: https://sites.google.com/view/ugirpi/

Link to download dataset from Zenodo: https://zenodo.org/record/2644617#.XLiuYuhKiNc
Dataset DOI: 10.5281/zenodo.2644617

Please cite the following paper when using this dataset for your research:

I. Bhattacharya, M. Foley, C. Ku, N. Zhang, T. Zhang, C. Mine, M. Li, H. Ji, C. Riedl, B. F. Welles, and R. J. Radke

"The Unobtrusive Group Interaction (UGI) Corpus", In Proceedings of the ACM Multimedia Systems. Amherst, MA, June 2019. 

